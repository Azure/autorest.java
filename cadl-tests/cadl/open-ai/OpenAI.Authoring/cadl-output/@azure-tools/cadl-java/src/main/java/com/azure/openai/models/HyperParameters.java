// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.openai.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonProperty;
import java.util.List;

/** The hyper parameter settings used in a fine tune job. */
@Fluent
public final class HyperParameters {
    /*
     * The batch size to use for training. The batch size is the number of training
     * examples used to train a single forward and backward pass.
     * In general, we've
     * found that larger batch sizes tend to work better for larger datasets.
     * The
     * default value as well as the maximum value for this property are specific to a
     * base model.
     */
    @JsonProperty(value = "batch_size")
    private Integer batchSize;

    /*
     * The learning rate multiplier to use for training. The fine-tuning learning rate
     * is the original learning rate used for pre-training multiplied by this
     * value.
     * Larger learning rates tend to perform better with larger batch
     * sizes.
     * We recommend experimenting with values in the range 0.02 to 0.2 to see
     * what produces the best results.
     */
    @JsonProperty(value = "learning_rate_multiplier")
    private Double learningRateMultiplier;

    /*
     * The number of epochs to train the model for. An epoch refers to one full cycle
     * through the training dataset.
     */
    @JsonProperty(value = "n_epochs")
    private Integer nEpochs;

    /*
     * The weight to use for loss on the prompt tokens. This controls how much the
     * model tries to learn to generate the prompt
     * (as compared to the completion
     * which always has a weight of 1.0), and can add a stabilizing effect to training
     * when completions are short.
     * If prompts are extremely long (relative to
     * completions), it may make sense to reduce this weight so as to avoid
     * over-prioritizing learning the prompt.
     */
    @JsonProperty(value = "prompt_loss_weight")
    private Double promptLossWeight;

    /*
     * A value indicating whether to compute classification metrics.
     * If set, we
     * calculate classification-specific metrics such as accuracy and F-1 score using
     * the validation set at the end of every epoch.
     * These metrics can be viewed in
     * the results file. In order to compute classification metrics, you must provide
     * a validation_file.Additionally,
     * you must specify classification_n_classes for
     * multiclass classification or classification_positive_class for binary
     * classification.
     */
    @JsonProperty(value = "compute_classification_metrics")
    private Boolean computeClassificationMetrics;

    /*
     * The number of classes in a classification task.
     * This parameter is required for
     * multiclass classification.
     */
    @JsonProperty(value = "classification_n_classes")
    private Integer classificationNClasses;

    /*
     * The positive class in binary classification.
     * This parameter is needed to
     * generate precision, recall, and F1 metrics when doing binary classification.
     */
    @JsonProperty(value = "classification_positive_class")
    private String classificationPositiveClass;

    /*
     * The classification beta values. If this is provided, we calculate F-beta scores
     * at the specified beta values.
     * The F-beta score is a generalization of F-1
     * score. This is only used for binary classification.
     * With a beta of 1 (i.e.the
     * F-1 score), precision and recall are given the same weight.
     * A larger beta
     * score puts more weight on recall and less on precision. A smaller beta score
     * puts more weight on precision and less on recall.
     */
    @JsonProperty(value = "classification_betas")
    private List<Double> classificationBetas;

    /** Creates an instance of HyperParameters class. */
    public HyperParameters() {}

    /**
     * Get the batchSize property: The batch size to use for training. The batch size is the number of training examples
     * used to train a single forward and backward pass. In general, we've found that larger batch sizes tend to work
     * better for larger datasets. The default value as well as the maximum value for this property are specific to a
     * base model.
     *
     * @return the batchSize value.
     */
    public Integer getBatchSize() {
        return this.batchSize;
    }

    /**
     * Set the batchSize property: The batch size to use for training. The batch size is the number of training examples
     * used to train a single forward and backward pass. In general, we've found that larger batch sizes tend to work
     * better for larger datasets. The default value as well as the maximum value for this property are specific to a
     * base model.
     *
     * @param batchSize the batchSize value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setBatchSize(Integer batchSize) {
        this.batchSize = batchSize;
        return this;
    }

    /**
     * Get the learningRateMultiplier property: The learning rate multiplier to use for training. The fine-tuning
     * learning rate is the original learning rate used for pre-training multiplied by this value. Larger learning rates
     * tend to perform better with larger batch sizes. We recommend experimenting with values in the range 0.02 to 0.2
     * to see what produces the best results.
     *
     * @return the learningRateMultiplier value.
     */
    public Double getLearningRateMultiplier() {
        return this.learningRateMultiplier;
    }

    /**
     * Set the learningRateMultiplier property: The learning rate multiplier to use for training. The fine-tuning
     * learning rate is the original learning rate used for pre-training multiplied by this value. Larger learning rates
     * tend to perform better with larger batch sizes. We recommend experimenting with values in the range 0.02 to 0.2
     * to see what produces the best results.
     *
     * @param learningRateMultiplier the learningRateMultiplier value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setLearningRateMultiplier(Double learningRateMultiplier) {
        this.learningRateMultiplier = learningRateMultiplier;
        return this;
    }

    /**
     * Get the nEpochs property: The number of epochs to train the model for. An epoch refers to one full cycle through
     * the training dataset.
     *
     * @return the nEpochs value.
     */
    public Integer getNEpochs() {
        return this.nEpochs;
    }

    /**
     * Set the nEpochs property: The number of epochs to train the model for. An epoch refers to one full cycle through
     * the training dataset.
     *
     * @param nEpochs the nEpochs value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setNEpochs(Integer nEpochs) {
        this.nEpochs = nEpochs;
        return this;
    }

    /**
     * Get the promptLossWeight property: The weight to use for loss on the prompt tokens. This controls how much the
     * model tries to learn to generate the prompt (as compared to the completion which always has a weight of 1.0), and
     * can add a stabilizing effect to training when completions are short. If prompts are extremely long (relative to
     * completions), it may make sense to reduce this weight so as to avoid over-prioritizing learning the prompt.
     *
     * @return the promptLossWeight value.
     */
    public Double getPromptLossWeight() {
        return this.promptLossWeight;
    }

    /**
     * Set the promptLossWeight property: The weight to use for loss on the prompt tokens. This controls how much the
     * model tries to learn to generate the prompt (as compared to the completion which always has a weight of 1.0), and
     * can add a stabilizing effect to training when completions are short. If prompts are extremely long (relative to
     * completions), it may make sense to reduce this weight so as to avoid over-prioritizing learning the prompt.
     *
     * @param promptLossWeight the promptLossWeight value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setPromptLossWeight(Double promptLossWeight) {
        this.promptLossWeight = promptLossWeight;
        return this;
    }

    /**
     * Get the computeClassificationMetrics property: A value indicating whether to compute classification metrics. If
     * set, we calculate classification-specific metrics such as accuracy and F-1 score using the validation set at the
     * end of every epoch. These metrics can be viewed in the results file. In order to compute classification metrics,
     * you must provide a validation_file.Additionally, you must specify classification_n_classes for multiclass
     * classification or classification_positive_class for binary classification.
     *
     * @return the computeClassificationMetrics value.
     */
    public Boolean isComputeClassificationMetrics() {
        return this.computeClassificationMetrics;
    }

    /**
     * Set the computeClassificationMetrics property: A value indicating whether to compute classification metrics. If
     * set, we calculate classification-specific metrics such as accuracy and F-1 score using the validation set at the
     * end of every epoch. These metrics can be viewed in the results file. In order to compute classification metrics,
     * you must provide a validation_file.Additionally, you must specify classification_n_classes for multiclass
     * classification or classification_positive_class for binary classification.
     *
     * @param computeClassificationMetrics the computeClassificationMetrics value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setComputeClassificationMetrics(Boolean computeClassificationMetrics) {
        this.computeClassificationMetrics = computeClassificationMetrics;
        return this;
    }

    /**
     * Get the classificationNClasses property: The number of classes in a classification task. This parameter is
     * required for multiclass classification.
     *
     * @return the classificationNClasses value.
     */
    public Integer getClassificationNClasses() {
        return this.classificationNClasses;
    }

    /**
     * Set the classificationNClasses property: The number of classes in a classification task. This parameter is
     * required for multiclass classification.
     *
     * @param classificationNClasses the classificationNClasses value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setClassificationNClasses(Integer classificationNClasses) {
        this.classificationNClasses = classificationNClasses;
        return this;
    }

    /**
     * Get the classificationPositiveClass property: The positive class in binary classification. This parameter is
     * needed to generate precision, recall, and F1 metrics when doing binary classification.
     *
     * @return the classificationPositiveClass value.
     */
    public String getClassificationPositiveClass() {
        return this.classificationPositiveClass;
    }

    /**
     * Set the classificationPositiveClass property: The positive class in binary classification. This parameter is
     * needed to generate precision, recall, and F1 metrics when doing binary classification.
     *
     * @param classificationPositiveClass the classificationPositiveClass value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setClassificationPositiveClass(String classificationPositiveClass) {
        this.classificationPositiveClass = classificationPositiveClass;
        return this;
    }

    /**
     * Get the classificationBetas property: The classification beta values. If this is provided, we calculate F-beta
     * scores at the specified beta values. The F-beta score is a generalization of F-1 score. This is only used for
     * binary classification. With a beta of 1 (i.e.the F-1 score), precision and recall are given the same weight. A
     * larger beta score puts more weight on recall and less on precision. A smaller beta score puts more weight on
     * precision and less on recall.
     *
     * @return the classificationBetas value.
     */
    public List<Double> getClassificationBetas() {
        return this.classificationBetas;
    }

    /**
     * Set the classificationBetas property: The classification beta values. If this is provided, we calculate F-beta
     * scores at the specified beta values. The F-beta score is a generalization of F-1 score. This is only used for
     * binary classification. With a beta of 1 (i.e.the F-1 score), precision and recall are given the same weight. A
     * larger beta score puts more weight on recall and less on precision. A smaller beta score puts more weight on
     * precision and less on recall.
     *
     * @param classificationBetas the classificationBetas value to set.
     * @return the HyperParameters object itself.
     */
    public HyperParameters setClassificationBetas(List<Double> classificationBetas) {
        this.classificationBetas = classificationBetas;
        return this;
    }
}
