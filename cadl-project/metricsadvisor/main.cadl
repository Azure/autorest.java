import "@cadl-lang/rest";
import "@cadl-lang/versioning";
import "./core.cadl";

using Cadl.Rest;
using Cadl.Versioning;

@serviceTitle("Adel")
@serviceVersion("2022-07-10-preview")
@doc("Adel API server.")
@Cadl.Rest.produces("application/json", "image/png")
@Cadl.Rest.consumes("application/json")
namespace Adel;

enum AlertConfigTypeValues {
  MultiVariateAnomaly,
  DataNotAvailable;
}

@knownValues(AlertConfigTypeValues)
model AlertConfigType is string {
}

enum HookTypeValues {
  Webhook,
  Emailhook;
}

@knownValues(HookTypeValues)
model HookType is string {
}

enum DataGranularityUnitValues {
  Minutes,
  Hours,
  Days,
  Weeks,
  Months,
  Years;
}

@knownValues(DataGranularityUnitValues)
model DataGranularityUnit is string {
}

enum DataSourceTypeValues {
  SqlServer
}

@knownValues(DataSourceTypeValues)
model DataSourceType is string {
}

enum AuthenticationTypeValues {
  ManagedIdentity;
}

@knownValues(AuthenticationTypeValues)
model AuthenticationType is string {
}

enum DataSchemaTypeValues {
  LongTable;
}

@knownValues(DataSchemaTypeValues)
model DataSchemaType is string {
}

enum AlignModeValues {
  Inner,
  Outer;
}

@knownValues(AlignModeValues)
model AlignMode is string {
}

enum FillNAMethodValues {
  Previous,
  Subsequent,
  Linear,
  Customized;
}

@knownValues(FillNAMethodValues)
model FillNAMethod is string {
}

enum ModelStatusValues {
  CREATED,
  RUNNING,
  COMPLETED,
  FAILED;
}

@knownValues(ModelStatusValues)
model ModelStatus is string {
}

enum EvaluationStatusValues {
  CREATED,
  RUNNING,
  COMPLETED,
  FAILED;
}

@knownValues(EvaluationStatusValues)
model EvaluationStatus is string {
}

enum ScheduleStatusValues {
  ACTIVE,
  CLIENTPAUSED,
  SERVERPAUSED;
}

@knownValues(ScheduleStatusValues)
model ScheduleStatus is string {
}

enum ReplayStatusValues {
  CREATED,
  RUNNING,
  COMPLETED,
  FAILED;
}

@knownValues(ReplayStatusValues)
model ReplayStatus is string {
}

enum OrderByValues {
  ASCENDING,
  DESCENDING;
}

@knownValues(OrderByValues)
model OrderBy is string {
}

@discriminator("hookType")
@doc("A hook is a channel to receive alert notifications.")
model Hook {    
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a hook. This parameter is case-sensitive.")
    hookName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of a hook.")
    hookDescription?: string;
    
    @visibility("read")
    @doc("The UTC time at which the hook was created.")
    createdTime: zonedDateTime;
    @visibility("read")
    @doc("The UTC time at which the parameter(s) of the hook was last modified by the users (if applicable).")
    parameterModifiedTime: zonedDateTime;
}

@doc("A webhook is a notification channel that sends alerts to a user-defined endpoint.")
model Webhook extends Hook {
    hookType: "Webhook";
    @doc("The API address to be called when an alert is triggered. MUST be Https.")
    endpoint: string;
    @doc("(Optional) Custom headers in the API call. A string map include key-value pairs.")
    header?: Map<string,string>;
    @doc("(Optional) For authenticating to the endpoint. Optional if authentication is not needed.")
    credential?: string;
}

@discriminator("alertConfigType")
@doc("Criteria that determine which anomalies should trigger an alert and via which notification channel(s). This setting can later be applied to a live inference schedule. ")
model AlertConfig {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of an alert configuration. This parameter is case-sensitive.")
    alertConfigName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of an alert configuration.")
    alertDescription?: string;
    
    @doc("(Optional) Specifies the list of notification channel(s) through which the alerts will be sent. If left blank, anomalies will still be detected but no alerts will be sent out. This parameter is case-sensitive.")
    hookNames?: string[];
    
    @visibility("read")
    @doc("The UTC time at which the alert configuration was created.")
    createdTime: zonedDateTime;
    @visibility("read")
    @doc("The UTC time at which the parameter(s) of the alert configuration was last modified by the users (if applicable).")
    parameterModifiedTime: zonedDateTime;
}

@doc("DataNotAvailable alert will be triggered if no data can be fetched from the data source.")
model DataNotAvailableAlertConfig extends AlertConfig {
    alertConfigType: "DataNotAvailable";
}

@doc("MultiVariateAnomaly alert will be triggered for anomalies detected on multivariate time-series data based on the criteria specified.")
model MultiVariateAnomalyAlertConfig extends AlertConfig {
    alertConfigType: "MultiVariateAnomaly";

    @minValue(0)
    @maxValue(100)
    @doc("An integer between 1 and 100. Set a lower sensitivity if you only want to be notified when severe anomalies are detected. Set a higher number if you want to report as many anomalies as possible.")
    sensitivity?: int32 = 70;

    @doc("The number of time-series data points to look back and correlate anomalies. For example, if the window is set to 5 and there is an anomaly at 01:30. Assume your data comes every 5 minutes, then the service will check if the last anomaly detected was within the past 25 minutes (i.e., window size * data frequency). If so, the service will correlate this new anomaly at 01:30 with the last anomaly and show an correlation ID in the alert notification. By default, the window is set to 0 and each anomaly is considered an individual incident.")
    @minValue(0)
    correlationWindow?: int32 = 0;

    @doc("True if you only want to receive one alert for each group of correlated anomalies (the alert will be sent for the earliest anomaly detected in this group). False if you want to receive an alert for every anomaly detected (regardless whether they are correlated or not).")
    suppressCorrelatedAlerts?: boolean = true;
}

@discriminator("dataSourceType")
@doc("Details about your data source, including data source type, location, authentication method, and so on.")
model DataSourceInfo {
    authenticationType: "ManagedIdentity";
}

@doc("Information required for Azure SQLServer data source type.")
model SqlServer extends DataSourceInfo {
    dataSourceType: "SqlServer";

    @doc("Name of a SQL Server.")
    serverName: string;
    @doc("Name of a SQL Database. This parameter is case-sensitive.")
    databaseName: string;
    @doc("Name of a SQL table or view. This parameter is case-sensitive.")
    tableName: string;
}

@discriminator("dataSchemaType")
@doc("Format and schema details of your data.")
model DataSchema {

}

@doc("A long-form data table has a single column that stores all the variables.")
model LongTable extends DataSchema {
    dataSchemaType: "LongTable";

    @doc("Header of the column that contains datetime values. This parameter is case-sensitive.")
    timestampColumnName: string;
    @doc("Header of the column that contains the name of the variable for each data point. This parameter is case-sensitive.")
    variableColumnName: string;
    @doc("Header of the column that contains numeric values. This parameter is case-sensitive. ")
    valueColumnName: string;
}

@doc("Summarizes information about the dataset, including name, description, data source type, data schema, data granualrity, and associated metadata. A dataset can be used for either training, evaluation, or real-time inference.")
model Dataset {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a dataset. This parameter is case-sensitive.")
    datasetName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of a dataset.")
    datasetDescirption?: string;

    @doc("Details about your data source, including data source type, location, authentication method, and so on.")
    dataSourceInfo: DataSourceInfo;
    @doc("Format and schema details of the dataset.")
    dataSchema: DataSchema;

    @minValue(1)
    @doc("The frequency interval at which new records are added to your data. Make sure that each variable has at most one data point within each interval.")
    dataGranularityNumber: int32;
    @doc("The unit of your data frequency interval.")
    dataGranularityUnit: DataGranularityUnit;

    @visibility("read")
    @doc("The UTC time at which the dataset was created.")
    createdTime: zonedDateTime;
}

@doc("Verify data schema and preview data before/after a dataset is created. View raw data to better diagnose and explain a detected anomaly.")
model DatasetPreviewRequest {
    @doc("Details about your data source, including data source type, location, authentication method, and so on.")
    dataSourceInfo: DataSourceInfo;
    @doc("Format and schema details of the dataset.")
    dataSchema: DataSchema;

    @minValue(1)
    @doc("The frequency interval at which new records are added to your data. Make sure that each variable has at most one data point within each interval.")
    dataGranularityNumber: int32;
    @doc("The unit of your data frequency interval.")
    dataGranularityUnit: DataGranularityUnit;

    @doc("The total number of rows to be returned. By default, the records are sorted by the timestamp column in descending order.")
    top?: int32;
    @doc("The list of time range(s) for which the data points will be returned. By default, there will be no filtering on time range and the number of records specified in the top field.")
    timeRange?: TimeRange;
    @doc("The list of variable(s) for which the data points will be returned. By default, all variables will be returned.")
    variablesFilter?: string[];
}

@doc("Returns data aligned to the data granularity.")
model DatasetPreviewResponse {
    @doc("Column headers.")
    columns: string[];
    @doc("Values for the corresponding columns headers. This values are aligned to the data granularity.")
    values: string[][];
}

@doc("Settings that control how variables are aligned to the same data frequency interval and how missing values are handled.")
model AlignPolicy {
    @doc("How to align variables to the same data frequency interval before further processing. Inner mode returns results on timestamps where EVERY variable has a value. Outer mode returns results on timestamps where ANY variable has a value. The default mode is Outer.")
    alignMode: AlignMode;
    @doc("How to populate any missing values in the dataset. The default method is Linear where missing values are filled by linear interpolation. If Customized method is selected, all missing values are filled by the value specified in paddingValue.")
    fillNAMethod: FillNAMethod;
    @doc("Specify the value to be used for Customized fillNAMethod. This is required if you chose Customized fillNAMethod but optional for other methods.")
    paddingValue?: float32;
}

@doc("Summarizes information about a model training process.")
model ModelState {
    @visibility("read")
    @doc("How many epochs the model has been trained out of a total of 100 epochs.")
    epochIds: int32[];
    @visibility("read")
    @doc("The training loss indicates how well the model fits the training data.")
    trainLosses: float32[];
    @visibility("read")
    @doc("The validation loss indicates how well the model fits the test data.")
    validationLosses: float32[];
    @visibility("read")
    @doc("The time cost for every 10 epochs.")
    latenciesInSeconds: float32[];
}

@doc("Summarizes information about each variable. Ranked by filledNARatio in descending order.")
model VariableState {
    @visibility("read")
    @doc("The name of the variable being used.")
    variable: string;

    @visibility("read")
    @minValue(0.0)
    @maxValue(1.0)
    @doc("Proportion of NaN values filled for the variable.")
    filledNARatio: float32;
    @visibility("read")
    @doc("Number of non-NaN data points for the variable.")
    effectiveCount: int32;

    @visibility("read")
    @doc("The first timestamp taken from the data source for a given variable. Different variables may have a different firstTimestamp due to missing values.")
    firstTimestamp: zonedDateTime;
    @visibility("read")
    @doc("The last timestamp taken from the data source for a given variable. Different variables may have a different lastTimestamp due to missing values.")
    lastTimestamp: zonedDateTime
}

@doc("Summarizes information about the model and each variable being used.")
model DiagnosticsInfo {
    @visibility("read")
    @doc("Summarizes information about the model, including name, description, training data, the number of variables being used, training status, and assoicated metadata.")
    modelState: ModelState;
    @visibility("read")
    @doc("Summarizes information about each variable being used. Ranked by filledNARatio in descending order.")
    variableStates: VariableState[]
}

@doc("A time range of data for processing. Both the start and end time are inclusive.")
model TimeRange {
    @doc("The first timestamp equal to or greater than the start time given will be processed.")
    startTime: zonedDateTime;
    @doc("The last timestamp equal to or less than the end time given will be processed. If endTime equals to startTime, one single data point will be processed.")
    endTime: zonedDateTime
}

@error
@doc("Error details for a failed job.")
model ErrorResponse {
    @visibility("read")
    @doc("The error code.")
    code: string;
    @visibility("read")
    @doc("The message explaining the error reported by the service.")
    message: string;
}

@doc("Summarizes information about the model, including name, description, training data, training time range(s), the number of variables being used, training status, and assoicated metadata.")
model Model {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a model. This parameter is case-sensitive.")
    modelName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of a model.")
    modelDescription?: string;

    @doc("Data used for model training. This parameter is case-sensitive.")
    datasetName: string;

    @doc("A list of time ranges used for model training. Both the start and end timestamps are inclusive.")
    trainingTimeRangeList: TimeRange[];

    @doc("Controls how many previous data points get used to determine if the next data point is an anomaly.")
    slidingWindow?: int32 = 300;
    @doc("Settings that control how variables are aligned to the same data frequency interval and how missing values are handled.")
    alignPolicy: AlignPolicy;

    @visibility("read")
    @doc("Summarizes information about the model and each variable being used.")
    diagnosticsInfo: DiagnosticsInfo;

    @visibility("read")
    @doc("Current status of the model training job.")
    status: ModelStatus;
    @visibility("read")
    @doc("The UTC time at which the training status of the model was last updated (if applicable).")
    statusUpdatedTime: zonedDateTime;
    @visibility("read")
    @doc("Error details if the model training job failed.")
    errors: ErrorResponse[];
    
    @visibility("read")
    @doc("The UTC time at which the model was created.")
    createdTime: zonedDateTime;
}

@doc("Summarizes information about the trained model, including name, description, training data, training time range(s), the number of varaiables being used, training status, and assoicated metadata.")
model ModelSnapshot {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a model. This parameter is case-sensitive.")
    modelName: string;
    @visibility("read")
    @maxLength(1024)
    @doc("(Optional) Detailed description of a model.")
    modelDescription?: string;

    @visibility("read")
    @doc("Data used for model training. This parameter is case-sensitive.")
    datasetName: string;

    @visibility("read")
    @doc("Number of variables used for model training.")
    variablesCount: int32;

    @visibility("read")
    @doc("Current status of the model training job.")
    status: ModelStatus;
    @visibility("read")
    @doc("The UTC time at which the training status of the model was last updated (if applicable).")
    statusUpdatedTime: zonedDateTime;

    @visibility("read")
    @doc("The UTC time at which the model was created.")
    createdTime: zonedDateTime;
}

@doc("Values for each timestamp of the variable.")
model VariableValues {
    @doc("The name of the variable.")
    name: string;
    @doc("The timestamp.")
    timestamps: string[];
    @doc("The value of the variable at the timestamp.")
    values: float32[];
}

@doc("The multivariate time-series data to be used for inference.")
model DetectionRequest {
    @doc("A list of variables to detect.")
    variables: VariableValues[];
    @doc("The first timestamp equal to or greater than the start time given will be processed.")
    startTime: zonedDateTime;
    @doc("The last timestamp equal to or less than the end time given will be processed. If endTime equals to startTime, one single data point will be processed.")
    endTime: zonedDateTime
}

@doc("A list of correlated variable(s) whose correlation with this contributing variable has changed significantly. This field can be empty if there were no significant correlation changes between the contributing variable and other variables.")
model CorrelationChanges {
    @visibility("read")
    @doc("The list of variable(s) whose correlation to the contributing variable has changed.")
    changedVariables: string[];
    @visibility("read")
    @doc("The extent to which the correlation(s) has changed.")
    changedValues: float32[];
}

@doc("Information on variables that contributed to a given anomaly. This field only applies to timestamps that are detected as anomalies.")
model AnomalyInterpretation {
    @visibility("read")
    @doc("Name of the top contributing variable to a given anomaly.")
    variable: string;
    @visibility("read")
    @doc("Higher contribution score indicates a higher possibility of this contributing variable being the root cause.")
    contributionScore: float32;
    @visibility("read")
    @doc("A list of correlated variable(s) whose correlation with this contributing variable has changed significantly. This field can be empty if there were no significant correlation changes between the contributing variable and other variables.")
    correlationChanges: CorrelationChanges;
}

@doc("Detection results for a given timestamp and information for diagnosing if the timestamp is an anomaly.")
model AnomalyValue {
    @visibility("read")
    @doc("True if the given timestamp is an anomaly.")
    isAnomaly: boolean;
    @visibility("read")
    @minValue(0.0)
    @maxValue(2.0)
    @doc("Raw output of the model.")
    score: float32;
    @visibility("read")
    @minValue(0.0)
    @maxValue(1.0)
    @doc("Indicates the significance of the anomaly. The higher the severity, the more significant the anomaly. Severity is 0 for normal timestamps (i.e., isAnomaly = false).")
    severity: float32;
    @visibility("read")
    @doc("A list containing information on variables that contributed to a given anomaly.")
    interpretation: AnomalyInterpretation[];
}

@doc("Summarizes the anomaly detection results for each timestamp.")
model AnomalyState {
    @visibility("read")
    @doc("The timestamp being detected.")
    timestamp: zonedDateTime;
    @visibility("read")
    @doc("Detection results for a given timestamp and information for diagnosing if the timestamp is an anomaly.")
    value: AnomalyValue;
    @visibility("read")
    @doc("Error details if the anomaly detection job failed.")
    errors: ErrorResponse[];
}

@doc("Summarizes information about the variables being used and the anomaly detection results for each timestamp.")
model DetectionResult {
    @visibility("read")
    @doc("Summarizes information about each variable being used. Ranked by filledNARatio in descending order.")
    variableStates: VariableState[];
    @visibility("read")
    @doc("Summarizes the anomaly detection results for each timestamp.")
    results: AnomalyState[];
    @visibility("read")
    @doc("Error details if the anomaly detection job failed.")
    errors: ErrorResponse[];
}

@doc("Specifies information about the model evaluation being used, including name, description, model, evaluation data, evaluation time range, status, and associated metadata.")
model Evaluation {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a model evaluation. This parameter is case-sensitive.")
    evaluationName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of a model evaluation.")
    evaluationDescription?: string;

    @doc("The model being evaluated. This parameter is case-sensitive.")
    modelName: string;

    @doc("The data being used to evaluate the model. This evaluation dataset should have the same schema and data granularity as the training dataset for the model. This parameter is case-sensitive.")
    datasetName: string;

    @doc("The first timestamp equal to or greater than the start time given will be used for model evaluation.")
    startTime: zonedDateTime;
    @doc("The last timestamp equal to or less than the end time given will be used for model evaluation. If endTime equals to startTime, one single data point will be processed.")
    endTime: zonedDateTime;

    @visibility("read")
    @doc("Current status of the model evaluation job.")
    status: EvaluationStatus;
    @visibility("read")
    @doc("The UTC time at which the status of the model evaluation job was last updated (if applicable).")
    statusUpdatedTime: zonedDateTime;
    @visibility("read")
    @doc("Error details if the model evaluation job failed.")
    errors: ErrorResponse[];

    @visibility("read")
    @doc("The Azure blob URL that stores the model evaluation results. This URL will expire in 12 hours.")
    resultUrl: string;
    @visibility("read")
    @doc("Summarizes information about each variable being used. Ranked by filledNARatio in descending order.")
    variableStates: VariableState[];

    @visibility("read")
    @doc("The UTC time at which the model evaluation job was created.")
    createdTime: zonedDateTime;
}

@doc("An inference schedule sets up a live inference pipeline to analyze new data in real-time. An inference schedule requires a unique name, a trained model, and a valid data source. You can also specify the criteria to trigger an anomaly alert and the channel(s) to receive alerts in an inference schedule.")
model Schedule {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a live streaming inference schedule. This parameter is case-sensitive.")
    scheduleName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of a live streaming inference schedule.")
    scheduleDescription?: string;
    
    @doc("The name of the previously trained model being used to create the live streaming inference schedule. This parameter is case-sensitive.")
    modelName: string;
    
    @doc("Data used for live streaming inference. This parameter is case-sensitive.")
    datasetName: string;

    @doc("(Optional) This start time can't be in the past. The first timestamp equal to or greater than the start time given will be used. Your data source must have data at the specified start time and the number of data points available must equal to or greater than your training sliding window.")
    startInferenceSince?: zonedDateTime;
    @doc("(Optional) The amount of time (in seconds) you expect the data to be delayed for inference. For example, your source data comes every 5 minutes, so by default (i.e., dataDelayOffsetInSeconds = 0) the inference schedule assumes that records with a timestamp of 01:30:00 will be ready for inference by 01:35:00, records with a timestamp of 01:35:00 will be ready at 01:40:00, and so on. If you expect a 10-minute data delay (i.e., dataDelayOffsetInSeconds = 600), then the scheduler will inference records with a timestamp of 01:30:00 at 01:45:00, inference records with a timestamp of 01:35:00 at 01:50:00, and so on.")
    dataDelayOffsetInSeconds?: int32 = 0;
    
    @doc("(Optional) Criteria that determine which anomalies should trigger an alert and via which notification channel(s). This parameter is case-sensitive.")
    alertConfigNames?: string[];
    
    @visibility("read")
    @doc("Current status of the inference schedule (ACTIVE/CLIENTPAUSED/SERVERPAUSED). CLIENTPAUSED means that the inference schedule was involuntarily paused by the user. SERVERPAUSED means that the inference schedule was involuntarily paused by the server and the detailed reasons can be found under scheduleStatusChangeInfo.")
    status: ScheduleStatus;
    @visibility("read")
    @doc("The UTC time at which the status of the inference schedule was last updated (if applicable).")
    statusUpdatedTime: zonedDateTime;
    @visibility("read")
    @doc("Detailed reasons if the inference schedule status changed to SERVERPAUSED.")
    scheduleStatusChangeInfo: string;

    @visibility("read")
    @doc("The last timestamp that was inferenced successfully.")
    lastSucceededTimestamp: zonedDateTime;

    @visibility("read")
    @doc("The UTC time at which the inference schedule was created.")
    createdTime: zonedDateTime;
    @visibility("read")
    @doc("The UTC time at which the parameter(s) of the hook was last modified by the users (if applicable).")
    parameterModifiedTime: zonedDateTime;
}

model ScheduleUpdate {
    @maxLength(1024)
    @doc("(Optional) Detailed description of a live streaming inference schedule.")
    scheduleDescription?: string;
    
    @doc("The name of the previously trained model being used to create the live streaming inference schedule. This parameter is case-sensitive.")
    modelName: string;
    
    @doc("(Optional) The amount of time (in seconds) you expect the data to be delayed for inference. For example, your source data comes every 5 minutes, so by default (i.e., dataDelayOffsetInSeconds = 0) the inference schedule assumes that records with a timestamp of 01:30:00 will be ready for inference by 01:35:00, records with a timestamp of 01:35:00 will be ready at 01:40:00, and so on. If you expect a 10-minute data delay (i.e., dataDelayOffsetInSeconds = 600), then the scheduler will inference records with a timestamp of 01:30:00 at 01:45:00, inference records with a timestamp of 01:35:00 at 01:50:00, and so on.")
    dataDelayOffsetInSeconds?: int32 = 0;
    
    @doc("(Optional) Criteria that determine which anomalies should trigger an alert and via which notification channel(s). This parameter is case-sensitive.")
    alertConfigNames?: string[];

    @doc("Current status of the inference schedule (ACTIVE/CLIENTPAUSED/SERVERPAUSED). CLIENTPAUSED means that the inference schedule was involuntarily paused by the user. SERVERPAUSED means that the inference schedule was involuntarily paused by the server and the detailed reasons can be found under scheduleStatusChangeInfo.")
    status: ScheduleStatus;
}

@doc("Re-inference a historical time range on an exiting inference schedule. The new anomaly detection results will overwrite the historical results in the replay time range but no alerts will be sent out.")
model ScheduleReplay {
    @key
    @visibility("read")
    @minLength(1)
    @maxLength(200)
    @pattern("\\w[\\w-_]{0,199}")
    @doc("Unique identifier of a replay on an inference schedule. This parameter is case-sensitive.")
    replayName: string;
    @maxLength(1024)
    @doc("(Optional) Detailed description of a replay on an inference schedule.")
    replayDescription?: string;

    @doc("The inference schedule whose settings will be used for replay. This parameter is case-sensitive.")
    scheduleName: string;

    @doc("The first timestamp equal to or greater than the start time given will be used for replay.")
    startTime: zonedDateTime;
    @doc("The last timestamp equal to or less than the end time given will be used for relay. If endTime equals to startTime, one single data point will be processed.")
    endTime: zonedDateTime;

    @visibility("read")
    @doc("Current status of the inference schedule replay job.")
    status: ReplayStatus;
    @visibility("read")
    @doc("The UTC time at which the status of the inference replay was last updated (if applicable).")
    statusUpdatedTime: zonedDateTime;
    @visibility("read")
    @doc("Error details if the inference replay job failed.")
    errors: ErrorResponse[];

    @visibility("read")
    @doc("Summarizes information about each variable being used. Ranked by filledNARatio in descending order.")
    variableStates: VariableState[];

    @visibility("read")
    @doc("The UTC time at which the inference replay job was created.")
    createdTime: zonedDateTime;   
}

@doc("Historical anomaly detection results for an inference schedule.")
model ScheduleHistoryResult {
    @visibility("read")
    @doc("Summarizes the anomaly detection results for each timestamp.")
    results: AnomalyState[];
}

model ListFilters {
  @doc("The number of records to skip from the list of records based on the sorting field and ordering method specified. By default, records are ranked by descending created time (UTC).")
  @Cadl.Http.query "skip"?: int32;

  @doc("The maximum number of records to be returned per page. If more records are requested via the API, @nextLink will contain the link to the next page.")
  @Cadl.Http.query "maxpagesize"?: int32;

  @doc("The name of the field on which you want to sort records. By default, records are sorted by created time (UTC).")
  @Cadl.Http.query "sortBy"?: string;

  @doc("Determines whether the records will be returned in descending or ascending order. By default, records are ranked in descending order.")
  @Cadl.Http.query "orderBy"?: OrderBy;
};

model ModelFilters {
  ... ListFilters;

  @doc("Filter models by one of the training statuses: CREATED, RUNNING, COMPLETED, or FAILED.")
  @Cadl.Http.query "status"?: ModelStatus;

  @doc("Filter models by a list of training dataset name(s). Format the list as a comma-separated string, no space allowed. For each dataset, by default the list of models are ranked by descending model created time (UTC).")
  @Cadl.Http.query "datasetNames"?: string;

  @doc("The total number of models to be returned per dataset, ordered by created time descending. By default, the full list of models will be returned for the dataset name(s) in your filter.")
  @Cadl.Http.query "topPerDataset"?: int32;
};

model EvaluationFilters {
  ... ListFilters;
  
  @doc("Filter model evaluations by one of the evaluation statuses: CREATED, RUNNING, COMPLETED, or FAILED.")
  @Cadl.Http.query "status"?: EvaluationStatus;

  @doc("Filter evaluations by a list of model name(s). Format the list as a comma-separated string, no space allowed. For each model, by default the list of evaluations are ranked by descending evaluation created time (UTC).")
  @Cadl.Http.query "modelNames"?: string;

  @doc("The total number of evaluations to be returned per model, ordered by created time descending. By default, the full list of evaluations will be returned for the model name(s) in your filter.")
  @Cadl.Http.query "topPerModel"?: int32;
};

model ScheduleFilters {
  ... ListFilters;
  
  @doc("Filter inference schedules by one of the schedule statuses: ACTIVE, CLIENTPAUSED or SERVERPAUSED.")
  @Cadl.Http.query "status"?: ScheduleStatus;

  @doc("Filter inference schedules by a list of model name(s). Format the list as a comma-separated string, no space allowed. For each model, by default the list of inference schedules are ranked by descending inference schedule created time (UTC).")
  @Cadl.Http.query "modelNames"?: string;
 
  @doc("The total number of inference schedules to be returned per model, ordered by created time descending. By default, the full list of inference schedules will be returned for the model name(s) in your filter.")
  @Cadl.Http.query "topPerModel"?: int32;
};

model ReplayFilters {
  ... ListFilters;
  
  @doc("Filter inference schedule replay by one of the replay statuses: CREATED, RUNNING, COMPLETED, or FAILED.")
  @Cadl.Http.query "status"?: ReplayStatus;

  @doc("Filter replay records by a list of inference schedule name(s). Format the list as a comma-separated string, no space allowed. By default, the list of replay records are ranked by descending replay created time (UTC) for each inference schedule.")
  @Cadl.Http.query "scheduleName"?: string;
 
  @doc("The total number of replay records to be returned per inference schedule, ordered by created time descending. By default, the full list of replay records will be returned for the inference schedule name(s) in your filter.")
  @Cadl.Http.query "topPerSchedule"?: int32;
};

@Cadl.Http.route("/alertConfigs")
interface AlertConfigs extends LifetimeOperations<AlertConfig, ListFilters> {
}

@Cadl.Http.route("/hooks")
interface Hooks extends LifetimeOperations<Hook, ListFilters> {
}

@Cadl.Http.route("/datasets")
interface Datasets extends LifetimeNoPatchOperations<Dataset, ListFilters> {
  @Cadl.Http.route("/previewData")
  @summary("Query data from data source to preview")
  @doc("Verify data schema and preview data before/after a dataset is created. View raw data to better diagnose and explain a detected anomaly.")
  @Cadl.Http.post op previewData(@Cadl.Http.body previewRequest: DatasetPreviewRequest): DatasetPreviewResponse | Error;
}

@Cadl.Http.route("/multivariate/models")
interface Models extends LifetimeNoPatchOperations<Model, ModelFilters> {
  @Cadl.Http.route("{modelName}/detect")
  @summary("Detect Multivariate Anomaly - Sync")
  @doc("Detect anomalies with a trained model and multivariate time-series data points specified in the request body. This API is recommended to be embedded in an inference schedule set up for continuous real-time inference. Please refer to the official documentation for the detailed quota and limits.")
  @Cadl.Http.post op detect(@Cadl.Http.path modelName: string, @Cadl.Http.body detectionRequest: DetectionRequest): DetectionResult | Error;
}

@Cadl.Http.route("/multivariate/evaluations")
interface Evaluations extends LifetimeNoPatchOperations<Evaluation, EvaluationFilters> {
}

using Cadl.Rest.Resource;

@Cadl.Http.route("/inference/schedules")
interface Schedules extends LifetimeNoPatchOperations<Schedule, ScheduleFilters> {
  @Cadl.Http.route("{scheduleName}/getHistory")
  @summary("Get historical detection results from the inference schedule")
  @doc("Use this API to retrieve detected anomalies over a historical time period specified in the request body. Please refer to the official documentation for the detailed quota and limits.")
  @Cadl.Http.get op getHistory(@Cadl.Http.path scheduleName: string, @Cadl.Http.query startTime: string, @Cadl.Http.query endTime: string): ScheduleHistoryResult | Error;

  @Cadl.Http.patch op update(... KeysOf<Schedule>, ... Updatable<ScheduleUpdate>): Schedule | Error;
}

@Cadl.Http.route("/inference/replays")
interface Replays extends LifetimeNoPatchOperations<ScheduleReplay, ReplayFilters> {
}
